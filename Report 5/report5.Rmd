---
title: "Report 5"
author: "Advay Vyas"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
urlcolor: blue
linkcolor: red
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(fig.height=4, fig.width=4, fig.align = "left", warning=FALSE, echo=TRUE, tidy=TRUE, tidy.opts=list(width.cutoff=60))
```

------------------------------------------------------------------------

```{r libraries, results='hide', warning=FALSE, message=FALSE, echo = FALSE}
library(dplyr)
library(tidyverse)
library(data.table)
library(ggplot2)
library(tigris)
library(stringr)
library(sf)
library(lubridate)
library(patchwork)
library(corrplot)
library(mosaic)
library(moderndive)
library(effectsize)
library(tidyr)
library(caret)
library(purrr)
library(fastDummies)
library(GGally)
library(formatR)
library(dbarts)
library(iml)
```

# Introduction
This week, I plan to improve predictions with the number of HSAs, adding season vs overall predictions, redoing the US map to include predictions even when I only have the main four predictors for BARRT

# Data processing
```{r process}
overall2 = read.csv("../forecasting_metrics_overall.csv")
pop_desc = read.csv("../us_hsa_county_popdesc.csv")

us_hsa_county_popdesc_bygroup <- pop_desc %>%
  select(state, hsa_nci_id, area_km2_hsa, area_km2_state, n_hsa) %>% 
  distinct()

overall <- overall2 %>%
  left_join(us_hsa_county_popdesc_bygroup, by = c("state", "hsa_nci_id"))

df_var <- overall %>% 
  filter(season == "2023/24", horizon == 3) %>%
  distinct()
```

# Predictions 
First, we implement the old model as before as a benchmark for improvement.
```{r old_fit}
bart_fit = bart(
  x.train = df_var[, c("pop_ratio","pct_urban",
                          "density_state","density_hsa")],
  y.train = df_var$diff_wis_season,
  verbose = FALSE, keeptrees = TRUE)

bart_vi = as.data.frame(bart_fit$varcount) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "avg") 

pred_old = predict(bart_fit, newdata = df_var)
bart_predictions = as.data.frame(t(apply(pred_old, 2, quantile, probs = c(0.025, 0.975))))
colnames(bart_predictions) = c("ci_low", "ci_high")

bart_predictions$estimate = apply(pred_old, 2, mean) 
bart_predictions$observed = df_var$diff_wis_season

coverage_95_bart = mean(
  bart_predictions$observed >= bart_predictions$ci_low &
  bart_predictions$observed <= bart_predictions$ci_high,
  na.rm = TRUE
)
```

## Adding number of HSAs
Now, let's add our new variables (the number of HSAs and the areas of the state and HSA).

### Season prediction
```{r szn_fit}
bart_fit_szn = bart(
  x.train = df_var[, c("pop_ratio","pct_urban","population_state","density_state",
          "density_hsa","n_hsa","area_km2_hsa","area_km2_state")],
  y.train = df_var$diff_wis_season,
  verbose = FALSE, keeptrees = TRUE)

bart_vi_szn = as.data.frame(bart_fit_szn$varcount) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "avg") 

pred_szn = predict(bart_fit_szn, newdata = df_var)
bart_predictions_szn = as.data.frame(t(apply(pred_szn, 2, quantile, probs = c(0.025, 0.975))))
colnames(bart_predictions_szn) = c("ci_low", "ci_high")

bart_predictions_szn$estimate = apply(pred_szn, 2, mean) 
bart_predictions_szn$observed = df_var$diff_wis_season

coverage_95_bart_szn = mean(
  bart_predictions_szn$observed >= bart_predictions_szn$ci_low &
  bart_predictions_szn$observed <= bart_predictions_szn$ci_high,
  na.rm = TRUE
)
```

### Overall prediction
```{r overall_fit}
bart_fit_overall = bart(
  x.train = df_var[, c("pop_ratio","pct_urban","population_state","density_state",
          "density_hsa","n_hsa","area_km2_hsa","area_km2_state")],
  y.train = df_var$diff_wis_season,
  verbose = FALSE, keeptrees = TRUE)

bart_vi_overall = as.data.frame(bart_fit_overall$varcount) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "avg") 

pred_overall = predict(bart_fit_overall, newdata = df_var)
bart_predictions_overall = as.data.frame(t(apply(pred_overall, 2, quantile, probs = c(0.025, 0.975))))
colnames(bart_predictions_overall) = c("ci_low", "ci_high")

bart_predictions_overall$estimate = apply(pred_overall, 2, mean) 
bart_predictions_overall$observed = df_var$diff_wis_season

coverage_95_bart_overall = mean(
  bart_predictions_overall$observed >= bart_predictions_overall$ci_low &
  bart_predictions_overall$observed <= bart_predictions_overall$ci_high,
  na.rm = TRUE
)
```

## Feature importance
Some (useful) feature importance graphs (in-built in BART) for each of the models, x-axis scaled to be the same.
```{r feature_imp, fig.width = 10, fig.height=8}
var_overall = ggplot(bart_vi_overall) + geom_col(aes(y = reorder(variable, avg), x = avg), fill='skyblue', col='black') + labs(y = "Feature", x = "Importance", title = "Feature importance (in-built, overall)") + coord_cartesian(xlim = c(0, 70))

var_szn = ggplot(bart_vi_szn) + geom_col(aes(y = reorder(variable, avg), x = avg), fill='skyblue', col='black') + labs(y = "Feature", x = "Importance", title = "Feature importance (in-built, season)") + coord_cartesian(xlim = c(0, 70))

var_old = ggplot(bart_vi) + geom_col(aes(y = reorder(variable, avg), x = avg), fill='skyblue', col='black') + labs(y = "Feature", x = "Importance", title = "Feature importance (in-built, old)") + coord_cartesian(xlim = c(0, 70))

var_old / var_szn / var_overall
```

```{r graphs, fig.width = 8, fig.height = 8, warning = FALSE, message= FALSE}
fig_szn = ggplot(bart_predictions_szn, aes(x = estimate, y = observed)) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0, alpha = 0.35) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Predicted diff_wis_season", y = "Observed diff_wis_season",
       title = "Observed vs Predicted with 95% Prediction Intervals (season)", 
       subtitle = sprintf("95%% coverage = %.1f%% (n=%d)", 100*coverage_95_bart_szn, nrow(bart_predictions_szn))) +
  theme_minimal() + scale_x_continuous(breaks=seq(-1,2,by=0.25)) + coord_cartesian(xlim = c(-0.25, 1))

fig_overall = ggplot(bart_predictions_overall, aes(x = estimate, y = observed)) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0, alpha = 0.35) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Predicted diff_wis_overall", y = "Observed diff_wis_overall",
       title = "Observed vs Predicted with 95% Prediction Intervals (overall)", 
       subtitle = sprintf("95%% coverage = %.1f%% (n=%d)", 100*coverage_95_bart_overall, nrow(bart_predictions_overall))) +
  theme_minimal() + scale_x_continuous(breaks=seq(-1,2,by=0.25)) + coord_cartesian(xlim = c(-0.25, 1))

fig_old = ggplot(bart_predictions, aes(x = estimate, y = observed)) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0, alpha = 0.35) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Predicted diff_wis_overall", y = "Observed diff_wis_overall",
       title = "Observed vs Predicted with 95% Prediction Intervals (old)", 
       subtitle = sprintf("95%% coverage = %.1f%% (n=%d)", 100*coverage_95_bart, nrow(bart_predictions))) +
  theme_minimal() + scale_x_continuous(breaks=seq(-1,2,by=0.25)) + coord_cartesian(xlim = c(-0.25, 1))

fig_old / fig_szn / fig_overall
```

# US map (again)
```{r map_data, cache=TRUE}
us_map = readRDS("../us_map_pop_sf.rds")
```

```{r map_process}
df_250 <- us_map %>%
  filter(population_hsa >= 250000) %>%
  select(state, hsa_nci_id, population_hsa, population_state, density_state,
         density_hsa, pct_urban, pop_ratio, geometry_hsa, geometry) %>%
  distinct() %>%
  distinct() %>%
  left_join(df_var %>%
              ungroup() %>%
              filter(season == '2023/24') %>%
              select(state, hsa_nci_id, diff_wis_season),
            by = c("state", "hsa_nci_id"))

pred <- predict(bart_fit, newdata = df_250) # picked the better one

df_pred <- df_250 %>%
  mutate(
    diff_wis_season_hat = apply(pred, 2, mean),
    lwr95               = apply(pred, 2, quantile, 0.025),
    upr95               = apply(pred, 2, quantile, 0.975)
  )
```

```{r map_generation, message=FALSE}
#all_inc <- read.csv("Local-level-forecasting/data/hsa_state_inc.csv")
all_inc <- readr::read_csv("../hsa_state_inc.csv", show_col_types = FALSE)

avail_hsa <- all_inc %>%
  select(state, hsa_nci_id, week_end) %>%
  group_by(state, hsa_nci_id) %>%
  summarise(max_week_end = max(week_end),
            min_week_end = min(week_end),
            n = n()) %>%
  filter(max_week_end == '2025-07-26')

lower48 <- c(state.name, "District of Columbia")  # 48 states  + DC
lower48 <- setdiff(lower48, c("Alaska", "Hawaii")) # not include Alaska and Hawaii

df_conus <- df_pred %>% 
  filter(state %in% lower48) %>%
  mutate(available = ifelse(is.na(diff_wis_season), 1, 0))

us_map1 <- us_map %>% 
  filter(state %in% lower48) %>%
  left_join(avail_hsa %>%
              filter(n == 148), by = c("state", "hsa_nci_id")) %>%
  mutate(available = ifelse(is.na(n), 0, 1))

hsa_included_map = ggplot() +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry_hsa"),
          aes(fill = factor(available)), color = 'gray20') +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry"),
          fill = NA, color = "grey20", linewidth = 0.25) +
  scale_fill_manual(values = c("0" = "white", "1" = "skyblue"),
                    name = "",
                    labels = c("Not in Data", "HSA in Data")) +
  coord_sf() +
  theme_void() +
  theme(
    legend.text  = element_text(size = 20)
  )

in_data_map = ggplot() +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(df_conus), "geometry_hsa"),
          aes(fill = diff_wis_season), color = 'gray20') +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry_hsa"),
          fill = NA, color = 'gray20') +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry"),
          fill = NA, color = "grey20", linewidth = 0.25) +
  scale_fill_viridis_c(option = "magma", direction = -1, na.value = "white",
                       name = "diff wis season") + 
  coord_sf() + theme_void() +
  labs(title = "diff wis season")

unavail_hsa <- us_map1 %>%  as.data.frame() %>% sf::st_as_sf() %>% sf::st_set_geometry("geometry_hsa") %>% dplyr::filter(available == 0, population_hsa > 250000)

predicted_map = ggplot() +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(df_conus), "geometry_hsa"),
          aes(fill = diff_wis_season_hat), color = 'gray20') +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry"),
          fill = NA, color = "grey20", linewidth = 0.25) +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry_hsa"),
          fill = NA, color = 'gray20') +
  geom_sf(data = unavail_hsa,
          fill = NA, color = "red", linewidth = 0.5) +
  scale_fill_viridis_c(option = "magma", direction = -1, na.value = "white",
                       name = "Prediction", 
                       limits = c(min(df_pred$diff_wis_season, na.rm = TRUE),
                                  max(df_pred$diff_wis_season, na.rm = TRUE))) +
  coord_sf() + theme_void() +
  labs(title = "Prediction")
```

These predicted graphs don't get to use n_hsa or the areas of HSA or state but every other variable is available. 
```{r us_map_graphs, cache=FALSE, fig.height = 10, fig.width = 10}
hsa_included_map / in_data_map / predicted_map

```

# SHAP (again)
## Season
We compute the SHAP scores in this code block 50 times (very computationally expensive).
```{r season_shap, cache=TRUE}
vars = c("pop_ratio","pct_urban","population_state","density_state",
          "density_hsa","n_hsa","area_km2_hsa","area_km2_state")

predictor_szn = Predictor$new(
  model = bart_fit_szn,
  data  = as.data.frame(df_var[ , vars]),
  y     = df_var$diff_wis_season,
  predict.function = function(object, newdata) {
    colMeans(predict(object, newdata = newdata))
  }
)


all_shap_szn = rbindlist(lapply(1:nrow(df_var), function(i) {
  sh = Shapley$new(
    predictor_szn,
    x.interest = df_var[i, vars],
    sample.size   = 50 
  )
  out = sh$results
  out$obs = i        
  out
}))
```

```{r season_shap_table}
global_imp_szn = all_shap_szn[, .(mean_abs_phi = mean(abs(phi))), by = feature]
knitr::kable(global_imp_szn[order(-mean_abs_phi)], caption = "(Season) Features by importance (descending)")
```

This graph basically discusses how much "movement" ($|\phi|$) each feature contributes in turning the baseline into the estimate. It is important to note that the correlation between some of these predictors might split or skew the feature importance. Namely, variables like population_state, area of the state, and density of the state all being predictors is okay because we are not using linear regression but SHAP finds it hard to account for it. 
```{r season_shap_graph, fig.width = 10}
ggplot(global_imp_szn, aes(x = reorder(feature, mean_abs_phi), y = mean_abs_phi)) +
  geom_col(fill='skyblue', col='black') +
  coord_flip() +
  labs(x = "Feature", y = "Mean of absolute value of SHAP",
       title = "(Season) Global SHAP feature importance")

```

## Overall
We compute the SHAP scores in this code block 50 times (very computationally expensive).
```{r shap_overall, cache=TRUE}
predictor_overall = Predictor$new(
  model = bart_fit_overall,
  data  = as.data.frame(df_var[ , vars]),
  y     = df_var$diff_wis_season,
  predict.function = function(object, newdata) {
    colMeans(predict(object, newdata = newdata))
  }
)


all_shap_overall = rbindlist(lapply(1:nrow(df_var), function(i) {
  sh = Shapley$new(
    predictor_overall,
    x.interest = df_var[i, vars],
    sample.size   = 50 
  )
  out = sh$results
  out$obs = i        
  out
}))
```

```{r overall_shap_table}
global_imp_overall = all_shap_overall[, .(mean_abs_phi = mean(abs(phi))), by = feature]
knitr::kable(global_imp_overall[order(-mean_abs_phi)], caption = "(Overall) Features by importance (descending)")
```

This graph basically discusses how much "movement" ($|\phi|$) each feature contributes in turning the baseline into the estimate. 
```{r overall_shap_graph, fig.width = 10}
ggplot(global_imp_overall, aes(x = reorder(feature, mean_abs_phi), y = mean_abs_phi)) +
  geom_col(fill='skyblue', col='black') +
  coord_flip() +
  labs(x = "Feature", y = "Mean of absolute value of SHAP",
       title = "(Overall) Global SHAP feature importance")

```

# Mixed/random effects with BART
I'm doing season only for this one, I'll see if it makes it better before comparing both methods. Let's see if this works out.
```{r rbart}
rbart_fit_szn = rbart_vi(
  formula = diff_wis_season ~ pop_ratio + pct_urban + population_state + 
                              density_state + density_hsa + n_hsa + 
                              area_km2_hsa + area_km2_state,
  data = df_var,
  group.by = df_var$state,   # random intercept per state
  n.trees = 150L,
                          k = 3.0,
                          n.samples = 2000L, n.burn = 1000L,
                          verbose = FALSE,
  keepTrees = TRUE
)

rpred_szn = predict(rbart_fit_szn, newdata = df_var, group.by = df_var$state, type = "ppd")   # expected value = f(x) + ranef

rbart_predictions_szn = as.data.frame(t(apply(rpred_szn, 2, quantile, probs = c(0.025, 0.975))))
colnames(rbart_predictions_szn) = c("ci_low", "ci_high")

rbart_predictions_szn$estimate = apply(rpred_szn, 2, mean) 
rbart_predictions_szn$observed = df_var$diff_wis_season

rcoverage_95_bart_szn = mean(
  rbart_predictions_szn$observed >= rbart_predictions_szn$ci_low &
  rbart_predictions_szn$observed <= rbart_predictions_szn$ci_high,
  na.rm = TRUE
)

```

```{r rbart_features}
rbart_vi_szn = as.data.frame(rbart_fit_szn$varcount) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "avg") 

mixed_features = ggplot(rbart_vi_szn) + geom_col(aes(y = reorder(variable, avg), x = avg), fill='skyblue', col='black') + labs(y = "Feature", x = "Importance", title = "Feature importance (in-built, season)") + coord_cartesian(xlim = c(0, 70))
```

```{r rbart_graph}
mixed_graph = ggplot(rbart_predictions_szn, aes(x = estimate, y = observed)) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0, alpha = 0.35) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Predicted diff_wis_season", y = "Observed diff_wis_season",
       title = "Observed vs Predicted with 95% Prediction Intervals (season)", 
       subtitle = sprintf("95%% coverage = %.1f%% (n=%d)", 100*rcoverage_95_bart_szn, nrow(rbart_predictions_szn))) +
  theme_minimal() + scale_x_continuous(breaks=seq(-1,2,by=0.25)) + coord_cartesian(xlim = c(-0.25, 1))

```

I do NOT know what this means. This is very scary.
```{r rbart_output, fig.width = 7, fig.height= 6}
mixed_features / mixed_graph
```
Now, I realize that I should have checked for differences between states before trying this out and having it fail spectacularly. Well, looks like Texas and maybe North Carolina are special cases that need to be dealt with separately.
```{r}
summary(lm(diff_wis_overall ~ state +  pop_ratio + pct_urban + population_state + density_state + density_hsa + n_hsa + area_km2_hsa + area_km2_state, data = df_var))
```

# Theoretical background of BART
I'm just reading through [this paper](https://arxiv.org/pdf/0806.3286) and taking notes to better understand what BART actually is.

Okay, the symbols and stuff got very confusing but I basically understand that it approximates $Y = f(x) + \epsilon$, where $\epsilon$ is noise, with a certain number of regression trees. Mainly reading the introduction here, this sum-of-trees is model is an "additive model with multivariate components". Boosting fits a sequence of trees, bagging/random forests use randomization to create independent trees. On the other hand, BART uses a sum of trees by imposing a prior that regularizes the fit by keeping the tree effects small. To fit the model, BART uses MCMC to construct and fit residuals. This model gives out distributions instead of point-wise results. I read a bit more about priors and MCMC being a random walk through a posterior distribution and this makes a lot more sense now. Yay!







