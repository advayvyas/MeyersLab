---
title: "Report 4"
author: "Advay Vyas"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
urlcolor: blue
linkcolor: red
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(fig.height=4, fig.width=4, fig.align = "center", warning=FALSE, echo=TRUE, tidy=TRUE, tidy.opts=list(width.cutoff=60))
```

------------------------------------------------------------------------

```{r, results='hide', warning=FALSE, message=FALSE, echo = FALSE}
library(dplyr)
library(tidyverse)
library(data.table)
library(ggplot2)
library(tigris)
library(stringr)
library(sf)
library(lubridate)
library(patchwork)
library(corrplot)
library(mosaic)
library(moderndive)
library(effectsize)
library(tidyr)
library(caret)
library(purrr)
library(fastDummies)
library(GGally)
library(dbarts)
library(iml)
```

# Introduction
This week, I cleaned some data, trained some new models on new data, looked at SHAP variable importance, and plotted results on a US map like in the other files.

# Data preprocessing
I took a quick glance at the new dataset's correlation matrix, for fun.
```{r, fig.height = 5, fig.width = 8}
df_new = read_csv("forecasting_metrics_overall.csv", show_col_types = FALSE)

df_new = df_new %>% 
  filter(season == "2023/24", horizon == 3) %>%
  distinct() %>% select(-included, -week_end_hsa, -week_end_state, -population_hsa, -season_week_hsa, -inc_hsa, 
                        -season_week_state, -inc_state)

cor_matrix = cor(df_new[, 5:ncol(df_new)])
# corrplot.mixed(cor_matrix, tl.col = "black", tl.pos = "lt", addgrid.col = TRUE, upper="color", lower="number", diag="l")
corrplot(cor_matrix, tl.col = "black", tl.pos = "l", addgrid.col = TRUE, type = "upper", method = "ellipse", diag = TRUE)
```

# Predicting with more variables
## Old predictions (overall)
```{r}
bart_fit <- bart(
  x.train = df_new[, c("pop_ratio","pct_urban",
                          "density_state","density_hsa")],
  y.train = df_new$diff_wis_season,
  verbose = FALSE, keeptrees = TRUE)

bart_vi = as.data.frame(bart_fit$varcount) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "avg") 

pred = predict(bart_fit, newdata = df_new)
bart_predictions = as.data.frame(t(apply(pred, 2, quantile, probs = c(0.025, 0.975))))
colnames(bart_predictions) = c("ci_low", "ci_high")

bart_predictions$estimate = (bart_predictions$ci_low + bart_predictions$ci_high) / 2
bart_predictions$observed = df_new$diff_wis_season

coverage_95_bart = mean(
  bart_predictions$observed >= bart_predictions$ci_low &
  bart_predictions$observed <= bart_predictions$ci_high,
  na.rm = TRUE
)
```

## Season predictions
```{r, fig.width = 7}
bart_fit_new = bart(
  x.train = df_new[, c("pop_ratio","pct_urban","density_state","density_hsa", "diff_peak_week", "diff_peak_magnitude", "rel_diff_peak_magnitude")],
  y.train = df_new$diff_wis_season,
  verbose = FALSE, keeptrees = TRUE
)

pred_new = predict(bart_fit_new, newdata = df_new)
bart_predictions_new = as.data.frame(t(apply(pred_new, 2, quantile, probs = c(0.025, 0.975))))
colnames(bart_predictions_new) = c("ci_low", "ci_high")

bart_predictions_new$estimate = apply(pred_new, 2, mean) 
bart_predictions_new$observed = df_new$diff_wis_season

coverage_95_bart_new = mean(
  bart_predictions_new$observed >= bart_predictions_new$ci_low &
  bart_predictions_new$observed <= bart_predictions_new$ci_high,
  na.rm = TRUE
)

bart_vi_new = as.data.frame(bart_fit_new$varcount) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "avg") 
```

## Overall predictions
```{r, fig.width = 7}
bart_fit_new2 = bart(
  x.train = df_new[, c("pop_ratio","pct_urban","density_state","density_hsa", "diff_peak_week", "diff_peak_magnitude", "rel_diff_peak_magnitude")],
  y.train = df_new$diff_wis_overall,
  verbose = FALSE, keeptrees = TRUE
)

pred_new2 = predict(bart_fit_new2, newdata = df_new)
bart_predictions_new2 = as.data.frame(t(apply(pred_new2, 2, quantile, probs = c(0.025, 0.975))))
colnames(bart_predictions_new2) = c("ci_low", "ci_high")

bart_predictions_new2$estimate = apply(pred_new2, 2, mean) 
bart_predictions_new2$observed = df_new$diff_wis_overall

coverage_95_bart_new2 = mean(
  bart_predictions_new2$observed >= bart_predictions_new2$ci_low &
  bart_predictions_new2$observed <= bart_predictions_new2$ci_high,
  na.rm = TRUE
)

bart_vi_new2 = as.data.frame(bart_fit_new2$varcount) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "avg") 
```

Some (useful) feature importance graphs (in-built in BART) for each of the models, x-axis scaled to be the same.
```{r, fig.width = 10}
var_new2 = ggplot(bart_vi_new2) + geom_col(aes(y = reorder(variable, avg), x = avg), fill='skyblue', col='black') + labs(y = "Feature", x = "Importance", title = "Feature importance (in-built, overall)") 
var_new = ggplot(bart_vi_new) + geom_col(aes(y = reorder(variable, avg), x = avg), fill='skyblue', col='black') + labs(y = "Feature", x = "Importance", title = "Feature importance (in-built, season)") 
var_old = ggplot(bart_vi) + geom_col(aes(y = reorder(variable, avg), x = avg), fill='skyblue', col='black') + labs(y = "Feature", x = "Importance", title = "Feature importance (in-built, old)")

(var_old + coord_cartesian(xlim = c(0, 70)))/ (var_new + coord_cartesian(xlim = c(0, 70))) / (var_new2 + coord_cartesian(xlim = c(0, 70)))
```

It looks like the season predictions look by far the best with a 79.2% coverage rate, followed by overall with a 71.7% coverage rate and lastly the old model with a 68.2% coverage rate (doesn't have those new variables). The graphs are below, stacked with scaled x-axes.
```{r, fig.width = 8, fig.height = 8, warning = FALSE, message= FALSE}
pred_new = ggplot(bart_predictions_new, aes(x = estimate, y = observed)) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0, alpha = 0.35) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Predicted diff_wis_season", y = "Observed diff_wis_season",
       title = "Observed vs Predicted with 95% Prediction Intervals (season)", 
       subtitle = sprintf("95%% coverage = %.1f%% (n=%d)", 100*coverage_95_bart_new, nrow(bart_predictions_new))) +
  theme_minimal() + scale_x_continuous(breaks=seq(-1,2,by=0.25))

pred_new2 = ggplot(bart_predictions_new2, aes(x = estimate, y = observed)) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0, alpha = 0.35) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Predicted diff_wis_overall", y = "Observed diff_wis_overall",
       title = "Observed vs Predicted with 95% Prediction Intervals (overall)", 
       subtitle = sprintf("95%% coverage = %.1f%% (n=%d)", 100*coverage_95_bart_new2, nrow(bart_predictions_new2))) +
  theme_minimal() + scale_x_continuous(breaks=seq(-1,2,by=0.25))

pred_old = ggplot(bart_predictions, aes(x = estimate, y = observed)) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0, alpha = 0.35) +
  geom_point(alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Predicted diff_wis_overall", y = "Observed diff_wis_overall",
       title = "Observed vs Predicted with 95% Prediction Intervals (old)", 
       subtitle = sprintf("95%% coverage = %.1f%% (n=%d)", 100*coverage_95_bart, nrow(bart_predictions))) +
  theme_minimal() + scale_x_continuous(breaks=seq(-1,2,by=0.25)) 

(pred_old + coord_cartesian(xlim = c(-0.25, 1.5))) / (pred_new + coord_cartesian(xlim = c(-0.25, 1.5))) / (pred_new2 + coord_cartesian(xlim = c(-0.25, 1.5)))
```

# US map generation
I used season data for this too because once again, it is better (and I implemented it first oops). I could also use the old model that only predicts using four variables and see if I can get some of those unavailable HSAs to register predicted values. Right now, sticking with this.
```{r, cache=TRUE}
us_map = readRDS("../us_map_pop_sf.rds")

df_250 <- us_map %>%
  filter(population_hsa >= 250000) %>%
  select(state, hsa_nci_id, population_hsa, population_state, density_state,
         density_hsa, pct_urban, pop_ratio, geometry_hsa, geometry) %>%
  distinct() %>%
  distinct() %>%
  left_join(df_new %>%
              ungroup() %>%
              filter(season == '2023/24') %>%
              select(state, hsa_nci_id, diff_wis_season, diff_peak_week, diff_peak_magnitude, rel_diff_peak_magnitude),
            by = c("state", "hsa_nci_id"))

# drop the bad stuff that doesnt have these cool new variables
df_250_complete <- df_250 %>%
  drop_na(diff_peak_week,
          diff_peak_magnitude,
          rel_diff_peak_magnitude)

pred <- predict(bart_fit_new, newdata = df_250_complete)

df_pred <- df_250_complete %>%
  mutate(
    diff_wis_season_hat = apply(pred, 2, mean),
    lwr95               = apply(pred, 2, quantile, 0.025),
    upr95               = apply(pred, 2, quantile, 0.975)
  )
```

```{r, cache=TRUE, message=FALSE}
#all_inc <- read.csv("Local-level-forecasting/data/hsa_state_inc.csv")
all_inc <- readr::read_csv("hsa_state_inc.csv", show_col_types = FALSE)

avail_hsa <- all_inc %>%
  select(state, hsa_nci_id, week_end) %>%
  group_by(state, hsa_nci_id) %>%
  summarise(max_week_end = max(week_end),
            min_week_end = min(week_end),
            n = n()) %>%
  filter(max_week_end == '2025-07-26')

lower48 <- c(state.name, "District of Columbia")  # 48 states  + DC
lower48 <- setdiff(lower48, c("Alaska", "Hawaii")) # not include Alaska and Hawaii

df_conus <- df_pred %>% 
  filter(state %in% lower48) %>%
  mutate(available = ifelse(is.na(diff_wis_season), 1, 0))

us_map1 <- us_map %>% 
  filter(state %in% lower48) %>%
  left_join(avail_hsa %>%
              filter(n == 148), by = c("state", "hsa_nci_id")) %>%
  mutate(available = ifelse(is.na(n), 0, 1))

# ggplot() +
#   geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry_hsa"),
#           aes(fill = factor(available)), color = 'gray20') +
#   geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry"),
#           fill = NA, color = "grey20", linewidth = 0.25) +
#   scale_fill_manual(values = c("0" = "white", "1" = "skyblue"),
#                     name = "",
#                     labels = c("Not in Data", "HSA in Data")) +
#   coord_sf() + 
#   theme_void() +
#   theme(
#     legend.text  = element_text(size = 20)
#   )

ggplot() +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(df_conus), "geometry_hsa"),
          aes(fill = diff_wis_season), color = 'gray20') +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry_hsa"),
          fill = NA, color = 'gray20') +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry"),
          fill = NA, color = "grey20", linewidth = 0.25) +
  scale_fill_viridis_c(option = "magma", direction = 1, na.value = "white",
                       name = "diff wis season") + 
  coord_sf() + theme_void() +
  labs(title = "diff wis season")

unavail_hsa <- us_map1 %>%
  as.data.frame() %>%              # 혹시 tibble이면 sf 변환 위해
  sf::st_as_sf() %>%
  sf::st_set_geometry("geometry_hsa") %>%
  dplyr::filter(available == 0, population_hsa > 250000)


ggplot() +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(df_conus), "geometry_hsa"),
          aes(fill = diff_wis_season_hat), color = 'gray20') +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry"),
          fill = NA, color = "grey20", linewidth = 0.25) +
  geom_sf(data = sf::st_set_geometry(sf::st_as_sf(us_map1), "geometry_hsa"),
          fill = NA, color = 'gray20') +
  geom_sf(data = unavail_hsa,
          fill = NA, color = "red", linewidth = 0.5) +
  scale_fill_viridis_c(option = "magma", direction = 1, na.value = "white",
                       name = "Prediction", 
                       limits = c(min(df_pred$diff_wis_season, na.rm = TRUE),
                                  max(df_pred$diff_wis_season, na.rm = TRUE))) +
  coord_sf() + theme_void() +
  labs(title = "Prediction")


```


# Variable importance with SHAP
I only did it with season since it takes forever to run and season did better. I can do it with overall if we want.
## One row
```{r, cache=TRUE}
predictor_new = Predictor$new(
  model = bart_fit_new,
  data  = df_new[, c("pop_ratio","pct_urban","density_state",
                     "density_hsa","diff_peak_week",
                     "diff_peak_magnitude","rel_diff_peak_magnitude")],
  y     = df_new$diff_wis_season,
  predict.function = function(object, newdata) {
    preds <- predict(object, newdata = newdata)
    colMeans(preds)
  }
)

shap_1 <- Shapley$new(
  predictor_new,
  x.interest = df_new[1, c("pop_ratio","pct_urban","density_state",
                           "density_hsa","diff_peak_week",
                           "diff_peak_magnitude","rel_diff_peak_magnitude")]
)
```

This graph is just one row of SHAP feature importance showing the raw $\phi$ scores (how much each variable shifted this estimate from the baseline) as an example.
```{r, fig.width = 10}
ggplot(shap_1$results, aes(x = reorder(feature, phi), y = phi)) +
  geom_col(fill='skyblue', col='black') +
  coord_flip() +
  labs(x = "Feature", y = "SHAP",
       title = "SHAP feature importance")
```

We compute the SHAP scores in this code block 50 times (very computationally expensive).
```{r, cache=TRUE}
vars = c("pop_ratio","pct_urban","density_state",
          "density_hsa","diff_peak_week",
          "diff_peak_magnitude","rel_diff_peak_magnitude")

predictor_new = Predictor$new(
  model = bart_fit_new,
  data  = as.data.frame(df_new[ , vars]),
  y     = df_new$diff_wis_season,
  predict.function = function(object, newdata) {
    colMeans(predict(object, newdata = newdata))
  }
)


all_shap = rbindlist(lapply(1:nrow(df_new), function(i) {
  sh = Shapley$new(
    predictor_new,
    x.interest = df_new[i, vars],
    sample.size   = 50 
  )
  out = sh$results
  out$obs = i        
  out
}))
```

```{r}
global_imp = all_shap[, .(mean_abs_phi = mean(abs(phi))), by = feature]
knitr::kable(global_imp[order(-mean_abs_phi)], caption = "Features by importance (descending)")
```

This graph basically discusses how much "movement" ($|\phi|$) each feature contributes in turning the baseline into the estimate. 
```{r, fig.width = 10}
ggplot(global_imp, aes(x = reorder(feature, mean_abs_phi), y = mean_abs_phi)) +
  geom_col(fill='skyblue', col='black') +
  coord_flip() +
  labs(x = "Feature", y = "Mean of absolute value of SHAP",
       title = "Global SHAP feature importance")

```

# Conclusion
I was able to see what variables were important with SHAP (the new ones were especially useful), improve the coverage rate drastically to the high 70s with these new "peak"-related variables, and also look at visualizations in US maps this week.